spark.executor.memory=<%= ENV["SPARK_EXECUTOR_MEMORY"] || '12g' %>
spark.driver.memory=<%= ENV["SPARK_DRIVER_MEMORY"] || '2g' %>
spark.executor.extraClassPath=/app/spark-home/lib/hadoop-aws-shaded.jar:/app/spark-home/lib/hadoop-lzo.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/httpclient-4.5.2.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/httpcore-4.4.4.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/commons-codec-1.9.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/commons-logging-1.2.jar
spark.driver.extraClassPath=/app/spark-home/lib/hadoop-aws-shaded.jar:/app/spark-home/lib/hadoop-lzo.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/httpclient-4.5.2.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/httpcore-4.4.4.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/commons-codec-1.9.jar:/app/spark-home/lib/httpcomponents-client-4.5.2/lib/commons-logging-1.2.jar
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.s3a.S3A
spark.hadoop.fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem
spark.hadoop.fs.s3n.multipart.uploads.block.size=536870912
spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec
spark.hadoop.io.compression.codec.lzo.class=com.hadoop.compression.lzo.LzoCodec

<% if ENV["ZEPPELIN_S3_AWS_ACCESS_KEY_ID"] && ENV["ZEPPELIN_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3a.awsAccessKeyId=<%= ENV["ZEPPELIN_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3a.awsSecretAccessKey=<%= ENV["ZEPPELIN_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3a.access.key=<%= ENV["ZEPPELIN_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3a.secret.key=<%= ENV["ZEPPELIN_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3n.awsAccessKeyId=<%= ENV["ZEPPELIN_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3n.awsSecretAccessKey=<%= ENV["ZEPPELIN_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3n.access.key=<%= ENV["ZEPPELIN_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3n.secret.key=<%= ENV["ZEPPELIN_S3_AWS_SECRET_ACCESS_KEY"] %>
<% end %>
